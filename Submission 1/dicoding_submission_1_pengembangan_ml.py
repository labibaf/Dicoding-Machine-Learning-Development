# -*- coding: utf-8 -*-
"""Dicoding Submission 1 Pengembangan ML

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QcGakAd1CXxDufLE7s0KgBsHhytLDCdG

## Submission 1 Pengembangan Machine Learing Dicoding
Labib Ammar Fadhali | labibfadhali12@gmail.com

**Konfigurasi Kaggle**
"""

!pip install -q kaggle

from google.colab import files
upload=files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d rajatrc1705/youtube-videos-dataset

!unzip '/content/youtube-videos-dataset.zip' -d '/content'

"""**Membaca Dataset**"""

import pandas as pd
df=pd.read_csv('/content/youtube.csv')

df.shape

df.head()

df.category.value_counts()

df.info()

"""**Membersihkan Data**"""

df.duplicated().sum()

df.isna().sum()

df.drop_duplicates(inplace=True)
df.duplicated().sum()

new_df=df.drop(columns='link',axis=1)
new_df

new_df['text'] = new_df['title'] + ' ' + new_df['description']
new_df=new_df.drop(columns=['title','description'],axis=1)
new_df

from bs4 import BeautifulSoup
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import re
nltk.download('stopwords')
nltk.download('punkt')

def remove_html_tags(text):
    soup = BeautifulSoup(text, 'html.parser')
    return soup.get_text()

def remove_url_and_brackets(text):
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'www\S+', '', text)
    text = re.sub(r'\([^)]*\)', '', text)
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\{.*?\}', '', text)
    return text

def remove_stopwords(text):
    stop_words = set(stopwords.words('english'))
    words = word_tokenize(text)
    filtered_words = [word for word in words if word.lower() not in stop_words]
    return ' '.join(filtered_words)

def clean_text(text):
  text=remove_html_tags(text)
  text=remove_url_and_brackets(text)
  text=remove_stopwords(text)
  return text

new_df['text'] = new_df['text'].apply(clean_text)
new_df

category=pd.get_dummies(new_df.category)
new_df=pd.concat([new_df,category],axis=1)
new_df=new_df.drop(columns='category',axis=1)
new_df

"""**Membagi Dataset menjadi 20% Validation Set**"""

text=new_df['text'].values
label=new_df[['art_music','food','history','travel']].values

from sklearn.model_selection import train_test_split

text_train,text_test,label_train,label_test=train_test_split(text,label,test_size=0.2)

print(len(text_train))
print(len(text_test))

"""**Menggunakan Tokenizer**"""

from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=10000, oov_token='<oov>')
tokenizer.fit_on_texts(text_train)

sekuens_train = tokenizer.texts_to_sequences(text_train)
sekuens_test = tokenizer.texts_to_sequences(text_test)

padded_train=pad_sequences(sekuens_train,padding='post',maxlen=75,truncating='post')
padded_test=pad_sequences(sekuens_test,padding='post',maxlen=75,truncating='post')

"""**Menggunakan Model Sequential, Menggunakan Embedding dan LSTM**"""

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=10000, output_dim=64),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(4, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""**Callback untuk menghentikan train jika accuracy dan val_accuracy lebih dari 90%**"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self,epoch,logs={}):
    if(logs.get('accuracy')>0.9) and (logs.get('val_accuracy')>0.9):
      print('\n accuracy and val_accuracy > 90%')
      self.model.stop_training=True
callbacks=myCallback()

"""**Melatih Model**"""

history=model.fit(padded_train,
                  label_train,
                  epochs=20,
                  validation_data=(padded_test,label_test),
                  verbose=2,
                  callbacks=[callbacks])

"""**Membuat Plot Loss dan Accuracy**"""

import matplotlib.pyplot as plt

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['Train','Test'],loc='upper right')
plt.show()

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['Train','Test'],loc='lower right')
plt.show()